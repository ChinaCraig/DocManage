# 智能关键词提取功能实现说明

## 概述

在原有LLM意图分析功能的基础上，我们进一步实现了智能关键词提取功能。当系统判断用户意图为向量库检索时，会先从用户的自然语言查询中提取最有效的搜索关键词，然后使用这些关键词进行向量数据库检索，显著提高查询准确率。

## 功能特性

### 🎯 **核心功能**
- **LLM关键词提取**: 使用大语言模型智能分析和提取关键词
- **备用分词机制**: 基于jieba的中文分词作为备用方案
- **查询优化**: 重组关键词形成更适合向量检索的查询
- **透明追踪**: 完整记录提取过程和结果

### 🔄 **处理流程**
```
用户输入 → 意图分析 → 向量检索意图？
    ↓ 是
关键词提取 → 查询优化 → 向量数据库检索
    ↓ 否
执行MCP操作
```

## 实现细节

### 新增方法

#### `LLMService.extract_search_keywords(query, llm_model)`
```python
"""
使用LLM从用户查询中提取最佳的搜索关键词

参数:
- query: 用户原始查询
- llm_model: LLM模型名称

返回:
{
  'original_query': str,      # 原始查询
  'keywords': List[str],      # 提取的关键词列表
  'optimized_query': str,     # 优化后的查询语句
  'reasoning': str,           # 提取依据
  'used_llm': bool           # 是否使用了LLM
}
"""
```

#### `LLMService._fallback_keyword_extraction(query)`
```python
"""
备用的基于jieba分词的关键词提取

特性:
- 中文分词处理
- 停用词过滤
- 标点符号清理
- 关键词数量控制(最多5个)
"""
```

### 集成到搜索路由

#### 语义搜索 (`/api/search/`)
```python
# 关键词提取流程
if llm_model:
    keyword_extraction = LLMService.extract_search_keywords(query_text, llm_model)
    search_query = keyword_extraction.get('optimized_query', query_text)
else:
    search_query = query_text

# 使用优化查询进行向量搜索
search_results = vector_service.search(search_query, top_k=top_k)
```

#### 混合搜索 (`/api/search/hybrid`)
```python
# 替换原有的query优化为关键词提取
if use_llm and llm_model:
    keyword_extraction = LLMService.extract_search_keywords(query_text, llm_model)
    optimized_query = keyword_extraction.get('optimized_query', query_text)

# 语义搜索和关键词搜索都使用优化查询
semantic_results = vector_service.search_similar(optimized_query, ...)
keyword_results = vector_service.search_by_keywords(optimized_query, ...)
```

## LLM提示词设计

### 系统提示词
```
你是一个专业的搜索关键词提取专家。你的任务是从用户的自然语言查询中提取最有效的搜索关键词。

关键词提取原则：
1. 提取核心概念和实体词汇
2. 去除停用词（的、是、在、了、等）
3. 保留重要的修饰词和限定词
4. 考虑同义词和相关词
5. 优先提取名词、专业术语
6. 保持2-5个关键词为最佳

优化查询原则：
1. 重新组织关键词形成简洁的查询
2. 保持查询的语义完整性
3. 适合向量相似度搜索
```

### 输出格式
```json
{
  "keywords": ["关键词1", "关键词2", "关键词3"],
  "optimized_query": "优化后的搜索查询",
  "reasoning": "关键词提取的依据"
}
```

## 备用分词机制

### jieba分词处理
```python
# 中文分词
words = list(jieba.cut(query))

# 停用词过滤
stop_words = {
    '的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一',
    '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看',
    '好', '自己', '这', '那', '里', '时', '把', '为', '但', '与', '及', '或',
    '等', '如', '由', '从', '以', '而', '且', '然后', '因为', '所以'
}

# 过滤逻辑
keywords = []
for word in words:
    word = word.strip()
    if (len(word) > 1 and 
        word not in stop_words and 
        not re.match(r'^[^\w\s]+$', word)):  # 排除纯标点
        keywords.append(word)
```

## API响应增强

### 语义搜索响应
```json
{
  "success": true,
  "data": {
    "query": "找一下银行贷款相关资料",
    "results": [...],
    "intent_analysis": {
      "intent_type": "vector_search",
      "confidence": 0.9,
      "action_type": "search_documents",
      "reasoning": "检测到搜索关键词",
      "used_llm": true
    },
    "keyword_extraction": {
      "original_query": "找一下银行贷款相关资料",
      "keywords": ["银行", "贷款", "资料"],
      "optimized_query": "银行 贷款 资料",
      "reasoning": "提取核心业务概念，去除搜索动词",
      "used_llm": true
    }
  }
}
```

### 混合搜索响应
```json
{
  "success": true,
  "data": {
    "query": "公司财务报表审计",
    "file_results": [...],
    "intent_analysis": {...},
    "keyword_extraction": {
      "original_query": "公司财务报表审计",
      "keywords": ["公司", "财务报表", "审计"],
      "optimized_query": "公司 财务报表 审计",
      "reasoning": "保留核心业务术语",
      "used_llm": true
    },
    "llm_info": {
      "used": true,
      "model": "openai:gpt-3.5-turbo",
      "original_query": "公司财务报表审计",
      "optimized_query": "公司 财务报表 审计",
      "query_optimized": true,
      "reranked": true,
      "answer": "..."
    }
  }
}
```

## 使用示例

### 查询优化对比

| 原始查询 | 提取关键词 | 优化查询 | 效果 |
|---------|-----------|----------|------|
| "帮我找一下关于银行贷款审批流程的相关文档" | ["银行", "贷款", "审批", "流程"] | "银行 贷款 审批 流程" | 去除冗余词，聚焦核心概念 |
| "我需要技术文档，特别是API接口说明书" | ["技术文档", "API", "接口", "说明书"] | "技术文档 API 接口 说明书" | 保留专业术语 |
| "查找所有的合同模板和法律条款文件" | ["合同", "模板", "法律", "条款"] | "合同 模板 法律 条款" | 提取实体概念 |

### API调用示例

```javascript
// 启用关键词提取的搜索
POST /api/search/
{
  "query": "找一下银行贷款相关资料",
  "llm_model": "openai:gpt-3.5-turbo",
  "enable_mcp": true,
  "top_k": 10
}

// 混合搜索与关键词提取
POST /api/search/hybrid
{
  "query": "公司财务报表和审计资料",
  "llm_model": "deepseek:deepseek-chat",
  "enable_llm": true,
  "enable_mcp": true,
  "similarity_level": "medium"
}
```

## 性能优化

### 降级策略
1. **LLM可用** → 使用LLM提取关键词
2. **LLM不可用** → 使用jieba分词提取
3. **分词失败** → 使用原始查询

### 缓存机制建议
- 对常见查询的关键词提取结果进行缓存
- 减少重复的LLM调用
- 提高响应速度

## 配置要求

### 依赖包
```bash
pip install jieba==0.42.1
```

### LLM模型支持
- OpenAI GPT系列
- DeepSeek Chat系列
- Ollama本地模型

## 效果评估

### 预期改进
1. **准确率提升**: 去除搜索噪音，聚焦核心概念
2. **相关性提高**: 优化后的查询更适合向量匹配
3. **用户体验**: 支持自然语言输入，无需手动提取关键词

### 测试用例
```python
test_cases = [
    "找一下关于银行贷款审批流程的相关文档",
    "帮我搜索公司财务报表和审计资料", 
    "查找所有的合同模板和法律条款文件",
    "我需要技术文档，特别是API接口说明书",
    "寻找人事管理制度和员工手册"
]
```

## 监控指标

### 关键指标
- 关键词提取成功率
- LLM调用延迟
- 搜索结果相关性分数
- 用户满意度反馈

### 日志记录
```python
logger.info(f"关键词提取完成 - 原查询: {query}, 关键词: {keywords}")
logger.warning(f"关键词提取失败，使用原查询: {error}")
```

这个智能关键词提取功能与之前的意图分析功能完美配合，形成了一个完整的智能搜索系统，能够更准确地理解用户意图并提供相关的搜索结果！ 